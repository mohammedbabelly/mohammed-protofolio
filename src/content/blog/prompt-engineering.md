---
title: "Prompt Engineering Still Matters in the Age of Powerful LLMs"
description: "Even with advanced models, crafting good prompts remains essential – here's why, plus tips from my recent talks."
pubDate: "Nov 20 2025"
heroImage: "/blog-prompt-engineering-talk.jpeg"
---

I've delivered my **Prompt Engineering for Generative AI** talk multiple times now – at AWS Community Dubai, Syrian Developers Gathering, Aleppo University, and more – and the feedback is always the same: people underestimate how much prompt quality still impacts output.

In 2025/2026, with models getting smarter every month, many think “just give it context and it'll figure it out.” But here's the truth:

- LLMs suffer from **confirmation bias** – they'll affirm whatever assumptions you sneak into the prompt
- Bad prompts → worse hallucinations, incomplete answers, or verbose nonsense
- Good engineering → precise, reliable, production-ready results

### Quick Tips I Share in Talks
1. **Be explicit** – structure your prompt with role, task, format, examples
2. **Use chain-of-thought** – “Think step by step”
3. **Provide context first** – facts before questions
4. **Iterate** – treat prompting like debugging code
5. **Avoid leading** – don't bias toward what you want to hear

I've seen huge improvements in code generation, architecture suggestions, and even homelab automation scripts just by refining prompts.

If you're using AI daily (who isn't?), investing 10 minutes in better prompting saves hours.

Watch the recording from Aleppo University (coming soon to YouTube) or reach out if you want the slides!

#AI #PromptEngineering #GenAI #developers